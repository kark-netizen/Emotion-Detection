{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1895b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from __future__ import absolute_import , division , print_function\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a79820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_running_time(start , end):\n",
    "    hours = int((end-start)/3600)\n",
    "    mins = int(((end-start)/60)%60)\n",
    "    secs = int((end - start)%3600)\n",
    "    print(\"Model Run Time: \")\n",
    "    print(hours,\":\",mins,\":\",secs)\n",
    "    return (hours,mins,secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23810d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train/'\n",
    "test_dir = 'dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421f676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "## loading dataset\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='training')\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='validation')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True)\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e139a766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11e7d198280>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(training_set[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5601d3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359 2 64\n"
     ]
    }
   ],
   "source": [
    "print( len(training_set) , len(training_set[0]) , len(training_set[0][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a4d7198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## labels\n",
    "class_labels = training_set.class_indices\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b87b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create  a model\n",
    "num_classes = 7\n",
    "weight_decay = 1e-3\n",
    "\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import regularizers\n",
    "\n",
    "def create_emotion_detection_model_1():\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(48,48,1)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(64, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (4,4), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"linear\"))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0003), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1ce61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create  a model\n",
    "num_classes = 7\n",
    "weight_decay = 1e-3\n",
    "\n",
    "def create_emotion_detection_model_2():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(48,48,1)),\n",
    "        keras.layers.Conv2D(filters=64 , kernel_size= (4,4), strides=(1,1) ,padding='valid' , kernel_regularizer=keras.regularizers.l2(weight_decay),activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D( filters=128 , kernel_size=(4,4) , strides = (1,1) , padding='valid' , activation='relu' , kernel_regularizer=keras.regularizers.l2(weight_decay)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        \n",
    "        keras.layers.Conv2D( filters = 128 , kernel_size=(4,4) , strides = (1,1) , padding='valid' , activation='relu' , kernel_regularizer=keras.regularizers.l2(weight_decay)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(units=256 , activation='relu'),\n",
    "        keras.layers.Dense(units=128 , activation='relu'),\n",
    "        keras.layers.Dense(units=128, activation='elu'),\n",
    "        \n",
    "        \n",
    "        keras.layers.Dense(units=num_classes , activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=Adam(0.0003), \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "905f40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'saved_models/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e852bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                            save_weights_only=True,\n",
    "                                            monitor='val_accuracy',\n",
    "                                            mode='max',\n",
    "                                            save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc8e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_emotion_detection_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9352270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 45, 45, 64)        1088      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 45, 45, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 45, 45, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 42, 42, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 42, 42, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 42, 42, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 21, 21, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 18, 18, 128)       262272    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 18, 18, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 18, 18, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 10368)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               2654464   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,100,615\n",
      "Trainable params: 3,099,975\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c758bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = training_set.n // training_set.batch_size\n",
    "validation_steps = validation_set.n // validation_set.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8250201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "358/358 [==============================] - 512s 1s/step - loss: 1.8528 - accuracy: 0.3583 - val_loss: 2.1590 - val_accuracy: 0.2198\n",
      "Epoch 2/10\n",
      "358/358 [==============================] - 507s 1s/step - loss: 1.5681 - accuracy: 0.4655 - val_loss: 1.7940 - val_accuracy: 0.4182\n",
      "Epoch 3/10\n",
      "358/358 [==============================] - 508s 1s/step - loss: 1.4187 - accuracy: 0.5192 - val_loss: 1.6868 - val_accuracy: 0.4858\n",
      "Epoch 4/10\n",
      "358/358 [==============================] - 508s 1s/step - loss: 1.3115 - accuracy: 0.5593 - val_loss: 1.8474 - val_accuracy: 0.4828\n",
      "Epoch 5/10\n",
      "358/358 [==============================] - 512s 1s/step - loss: 1.2196 - accuracy: 0.5944 - val_loss: 2.1650 - val_accuracy: 0.4428\n",
      "Epoch 6/10\n",
      "358/358 [==============================] - 510s 1s/step - loss: 1.1388 - accuracy: 0.6233 - val_loss: 1.6635 - val_accuracy: 0.5184\n",
      "Epoch 7/10\n",
      "358/358 [==============================] - 505s 1s/step - loss: 1.0498 - accuracy: 0.6581 - val_loss: 1.7935 - val_accuracy: 0.5063\n",
      "Epoch 8/10\n",
      "358/358 [==============================] - 510s 1s/step - loss: 0.9757 - accuracy: 0.6866 - val_loss: 1.9889 - val_accuracy: 0.4884\n",
      "Epoch 9/10\n",
      "358/358 [==============================] - 465s 1s/step - loss: 0.8786 - accuracy: 0.7265 - val_loss: 2.1541 - val_accuracy: 0.4900\n",
      "Epoch 10/10\n",
      "358/358 [==============================] - 463s 1s/step - loss: 0.7864 - accuracy: 0.7573 - val_loss: 2.1733 - val_accuracy: 0.4930\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.fit(x=training_set,\n",
    "                 validation_data=validation_set,\n",
    "                 epochs=10,\n",
    "                 callbacks=[cp_callback],\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ebd67f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Run Time: \n",
      "1 : 23 : 1398\n"
     ]
    }
   ],
   "source": [
    "_ = model_running_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "683b948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = create_emotion_detection_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed0a504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 44s 392ms/step - loss: 2.0948 - accuracy: 0.5011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.09478497505188, 0.5011144876480103]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_weights(checkpoint_path)\n",
    "new_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adb59e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "123/358 [=========>....................] - ETA: 4:58 - loss: 0.6831 - accuracy: 0.8030"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KARTIK~1\\AppData\\Local\\Temp/ipykernel_21020/3080979335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m new_model.fit(x=training_set,\n\u001b[0m\u001b[0;32m      4\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "new_model.fit(x=training_set,\n",
    "                 validation_data=validation_set,\n",
    "                 epochs=15,\n",
    "                 callbacks=[cp_callback],\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcdae3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 18s 163ms/step - loss: 1.7676 - accuracy: 0.5534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7675926685333252, 0.5533574819564819]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63f5ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "358/358 [==============================] - 440s 1s/step - loss: 0.6850 - accuracy: 0.7996 - val_loss: 2.0931 - val_accuracy: 0.5279\n",
      "Epoch 2/5\n",
      "358/358 [==============================] - 434s 1s/step - loss: 0.6059 - accuracy: 0.8318 - val_loss: 2.3704 - val_accuracy: 0.5154\n",
      "Epoch 3/5\n",
      "358/358 [==============================] - 435s 1s/step - loss: 0.5371 - accuracy: 0.8536 - val_loss: 2.6135 - val_accuracy: 0.4724\n",
      "Epoch 4/5\n",
      "358/358 [==============================] - 433s 1s/step - loss: 0.4885 - accuracy: 0.8729 - val_loss: 2.1998 - val_accuracy: 0.5409\n",
      "Epoch 5/5\n",
      "358/358 [==============================] - 490s 1s/step - loss: 0.4465 - accuracy: 0.8860 - val_loss: 2.3271 - val_accuracy: 0.5392\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "new_model.fit(x=training_set,\n",
    "                 validation_data=validation_set,\n",
    "                 epochs=5,\n",
    "                 callbacks=[cp_callback],\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "331b2ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 21s 182ms/step - loss: 2.2610 - accuracy: 0.5461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2610116004943848, 0.546113133430481]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6b9b7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e0ba2a730>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb9e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
